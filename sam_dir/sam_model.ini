#the parameter file for deep learning network setting

##############################################################
#sam_dir = ~/codes/github_public_repositories/segment-anything
sam_dir = ~/codes/github_public_repositories/sam2
python = ~/programs/miniconda3/envs/mapping/bin/python

# str type, "1" for segment anything model, "2" for sam2
sam_version = '2'

# defined the pre-trained model (~/Data/models_deeplearning/segment-anything)
# checkpoint = ~/Data/models_deeplearning/segment-anything/sam_vit_h_4b8939.pth
# for checkpoint for sam2: ~/Data/models_deeplearning/sam2
checkpoint = ~/Data/models_deeplearning/sam2/sam2.1_hiera_tiny.pt

# can be added or modified by the fine-tuned script
finedtuned_model = exp5/finetuned_exp5.pth

# model_type: default, vit_h, vit_l, vit_b  (default is vit_h)
#model_type = vit_h
# for sam2, model_type is the config files, in ~/codes/github_public_repositories/sam2/sam2/configs/sam2.1
# sam2.1_hiera_b+.yaml, sam2.1_hiera_l.yaml, sam2.1_hiera_s.yaml, sam2.1_hiera_t.yaml
model_type = ~/codes/github_public_repositories/sam2/sam2/configs/sam2.1/sam2.1_hiera_t.yaml

checkpoint_url = https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth

## training parameter
batch_size=1

# if this is set, iteration_num will be ignored, then iteration_num=train_epoch_num*train_sample_count/batch_size
train_epoch_num = 10

#base_learning_rate
base_learning_rate=0.001

weight_decay = 0.0005

##############################################################

